
# RVV-SIMD: Biblioteca SIMD Otimizada para RISC-V Vector

[![Documentation Status](https://readthedocs.org/projects/rvv-simd/badge/?version=latest)](https://rvv-simd.readthedocs.io/pt_BR/latest/?badge=latest)

[![Build Status](https://img.shields.io/badge/build-passing-brightgreen)](https://github.com/JPEDROPS092/sop/actions)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python Version](https://img.shields.io/badge/python-3.6%20%7C%203.7%20%7C%203.8%20%7C%203.9%20%7C%203.10-blue.svg)](https://www.python.org/downloads/)
[![pybind11](https://img.shields.io/badge/bindings-pybind11-orange.svg)](https://github.com/pybind/pybind11)
[![NumPy](https://img.shields.io/badge/numpy-compatible-green.svg)](https://numpy.org/)
[![RISC-V](https://img.shields.io/badge/RISC--V-RVV-red.svg)](https://riscv.org/)

Uma biblioteca SIMD (Single Instruction, Multiple Data) de alto desempenho otimizada para a extens√£o vetorial de RISC-V (RVV), com bindings Python, projetada para aplica√ß√µes de machine learning e processamento de dados.

<p align="center">
  <img src="https://riscv.org/wp-content/uploads/2020/06/riscv-color.svg" alt="RISC-V Logo" width="200"/>
</p>

## üìö Documenta√ß√£o

A documenta√ß√£o completa da biblioteca est√° dispon√≠vel no [Read the Docs](https://rvv-simd.readthedocs.io/pt_BR/latest/).

Para gerar a documenta√ß√£o localmente:

```bash
# Instalar depend√™ncias
pip install sphinx sphinx_rtd_theme breathe exhale

# Gerar documenta√ß√£o
cd docs
sphinx-build -b html . _build/html

# Visualizar documenta√ß√£o
python -m http.server 8000 --directory _build/html
```

## üìã Sum√°rio

1. [üìñ Introdu√ß√£o](#-introdu√ß√£o)
2. [üèóÔ∏è Arquitetura](#Ô∏è-arquitetura)
3. [‚öôÔ∏è Instala√ß√£o](#Ô∏è-instala√ß√£o)
4. [üíª Uso da Biblioteca em C++](#-uso-da-biblioteca-em-c)
5. [üêç Uso da Biblioteca em Python](#-uso-da-biblioteca-em-python)
6. [üìä Benchmarks Comparativos](#-benchmarks-comparativos)
7. [üß† Aplica√ß√µes em Machine Learning](#-aplica√ß√µes-em-machine-learning)
8. [‚ö° Otimiza√ß√µes para RVV](#-otimiza√ß√µes-para-rvv)
9. [üîÑ Alternativas e Compara√ß√£o](#-alternativas-e-compara√ß√£o)
10. [üìù Estado Atual do Suporte Python](#-estado-atual-do-suporte-python)
11. [üìÇ Estrutura do Projeto](#-estrutura-do-projeto)
12. [ü§ù Contribui√ß√µes](#-contribui√ß√µes)
13. [üìÑ Licen√ßa](#-licen√ßa)
14. [üôè Agradecimentos](#-agradecimentos)
15. [‚ùì Perguntas Frequentes](#-perguntas-frequentes)

## üìñ Introdu√ß√£o

A biblioteca RVV-SIMD √© uma implementa√ß√£o de opera√ß√µes SIMD otimizadas para a extens√£o vetorial de RISC-V (RVV). Esta biblioteca visa preencher uma lacuna importante no ecossistema RISC-V, especialmente em aplica√ß√µes de machine learning (ML) e outras √°reas que se beneficiam de processamento paralelo intensivo.

### üéØ Motiva√ß√£o

A escassez de bibliotecas otimizadas para RVV tem sido um obst√°culo para a ado√ß√£o mais ampla do RISC-V em aplica√ß√µes de ML. Esta biblioteca foi desenvolvida para:

1. **Explorar o potencial da extens√£o vetorial de RISC-V**: Utilizando instru√ß√µes RVV para acelerar opera√ß√µes paralelas.
2. **Democratizar o acesso √† computa√ß√£o vetorial em RISC-V**: Atrav√©s de bindings Python que facilitam a integra√ß√£o com frameworks populares.
3. **Fornecer benchmarks comparativos**: Comparando o desempenho com arquiteturas x86 (usando AVX) e ARM (usando NEON).
4. **Suportar aplica√ß√µes de ML**: Implementando opera√ß√µes comuns em redes neurais e outros algoritmos de ML.

### ‚ú® Caracter√≠sticas Principais

* **Opera√ß√µes vetoriais otimizadas**: Implementa√ß√µes eficientes de opera√ß√µes b√°sicas em vetores.
* **Opera√ß√µes matriciais**: Suporte a opera√ß√µes em matrizes, incluindo multiplica√ß√£o e transposi√ß√£o.
* **Opera√ß√µes de ML**: Implementa√ß√µes de convolu√ß√£o, pooling, batch normalization e outras opera√ß√µes comuns em ML.
* **Bindings Python**: Interface Python completa, compat√≠vel com NumPy.
* **Benchmarks comparativos**: Ferramentas para comparar o desempenho com x86 (AVX) e ARM (NEON).
* **Implementa√ß√µes de fallback**: C√≥digo escalar para plataformas sem suporte a RVV, garantindo portabilidade.
* **Documenta√ß√£o abrangente**: Exemplos detalhados e documenta√ß√£o para facilitar o uso.

## üèóÔ∏è Arquitetura

A biblioteca RVV-SIMD √© estruturada em camadas para fornecer tanto opera√ß√µes de baixo n√≠vel otimizadas quanto interfaces de alto n√≠vel para aplica√ß√µes de ML e processamento de dados.

### üß© Componentes Principais

#### üîß Biblioteca Core (C++)

A biblioteca core √© implementada em C++ e consiste nos seguintes componentes:

1. **Opera√ß√µes Vetoriais**:
   * Opera√ß√µes aritm√©ticas b√°sicas (adi√ß√£o, subtra√ß√£o, multiplica√ß√£o, divis√£o)
   * Produto escalar (dot product)
   * Escalonamento de vetores
   * Normaliza√ß√£o de vetores
   * Fun√ß√µes matem√°ticas (exp, log, sigmoid, tanh, ReLU)

2. **Opera√ß√µes Matriciais**:
   * Opera√ß√µes aritm√©ticas em matrizes (adi√ß√£o, subtra√ß√£o, multiplica√ß√£o elemento a elemento)
   * Multiplica√ß√£o de matrizes
   * Transposi√ß√£o de matrizes
   * Escalonamento de matrizes
   * Normas de matrizes

3. **Opera√ß√µes de Machine Learning**:
   * Opera√ß√µes de convolu√ß√£o para CNNs
   * Opera√ß√µes de pooling (max, average)
   * Batch normalization
   * Fun√ß√µes de ativa√ß√£o (softmax)
   * Fun√ß√µes de perda (cross-entropy)
   * C√°lculo de gradientes

#### üêç Bindings Python

Os bindings Python, implementados com `pybind11`, fornecem uma interface de alto n√≠vel para a biblioteca core, tornando-a acess√≠vel para usu√°rios Python e integrando-a com o ecossistema de ci√™ncia de dados do Python:

* Interface compat√≠vel com NumPy (aceita e retorna arrays NumPy)
* Suporte para arrays multidimensionais
* Integra√ß√£o facilitada com frameworks de ML do Python (PyTorch, TensorFlow, etc.)
* API intuitiva com nomes de fun√ß√µes familiares para usu√°rios de NumPy

### Diagrama de Arquitetura

```
+---------------------+
|    Camada Python    |
| (Compat√≠vel NumPy)  |
+----------+----------+
           |
           v
+----------+----------+
|   Bindings Python   |
|     (pybind11)      |
+----------+----------+
           |
           v
+---------------------+
| Biblioteca Core C++ |
+---------------------+
|  Opera√ß√µes Vetoriais|
|  Opera√ß√µes Matriciais|
|  Opera√ß√µes de ML    |
+----------+----------+
           |
           v
+---------------------+    +------------------------+
| Instru√ß√µes Vetoriais|--->| Implementa√ß√£o Fallback |
|     RISC-V (RVV)    |    |    (Escalar / C++)     |
+---------------------+    +------------------------+
 (Se suportado)             (Se RVV n√£o suportado)
```

### Detalhes de Implementa√ß√£o

#### Extens√£o Vetorial RISC-V (RVV)

A biblioteca utiliza intr√≠nsecos vetoriais RISC-V (`<riscv_vector.h>`) quando compilada para hardware compat√≠vel. As otimiza√ß√µes aproveitam a flexibilidade da RVV, como o ajuste din√¢mico do comprimento do vetor (`vl`) e o uso eficiente dos registradores vetoriais. Principais intr√≠nsecos utilizados incluem:

*   `__riscv_vsetvl_e32m8` (e variantes): Define o comprimento do vetor para processamento.
*   `__riscv_vle32_v_f32m8`: Carrega elementos de mem√≥ria para registradores vetoriais.
*   `__riscv_vse32_v_f32m8`: Armazena elementos de registradores vetoriais na mem√≥ria.
*   `__riscv_vfadd_vv_f32m8`, `vfsub`, `vfmul`, `vfdiv`: Opera√ß√µes aritm√©ticas vetoriais.
*   `__riscv_vfmacc_vv_f32m8`: Multiplica√ß√£o-acumula√ß√£o vetorial (√∫til em matmul, conv).
*   `__riscv_vfredusum_vs_f32m8_f32m1`: Redu√ß√£o de soma vetorial (√∫til em dot product).
*   Opera√ß√µes de m√°scara para execu√ß√£o condicional.

#### Implementa√ß√µes de Fallback

Para garantir a portabilidade e usabilidade em plataformas RISC-V sem a extens√£o vetorial ou em outras arquiteturas (para fins de teste/compara√ß√£o), a biblioteca fornece implementa√ß√µes escalares puras em C++ para todas as opera√ß√µes. A sele√ß√£o entre a implementa√ß√£o RVV e a de fallback √© feita em tempo de compila√ß√£o usando diretivas de pr√©-processador (`#ifdef __riscv_vector`).

## Instala√ß√£o

### Pr√©-requisitos

*   **Toolchain RISC-V**: Compilador (GCC ou Clang) com suporte √† extens√£o vetorial (`-march=rv64gcv` ou similar).
*   **CMake**: Vers√£o 3.10 ou superior.
*   **Python**: Vers√£o 3.6 ou superior (necess√°rio apenas para os bindings Python).
*   **pybind11**: Biblioteca C++ para criar bindings Python (geralmente inclu√≠da como subm√≥dulo ou baixada pelo CMake).
*   **NumPy**: Biblioteca Python para manipula√ß√£o de arrays (necess√°ria para os exemplos e testes Python).

### Compilando a partir do C√≥digo Fonte

1.  **Clone o reposit√≥rio:**
    ```bash
    git clone https://github.com/<your_username>/rvv-simd.git # Substitua pelo URL real
    cd rvv-simd
    # Opcional: Inicializar subm√≥dulos (se pybind11 for um subm√≥dulo)
    # git submodule update --init --recursive
    ```

2.  **Crie um diret√≥rio de build e configure com CMake:**
    ```bash
    mkdir build && cd build
    # Para build padr√£o (detectar√° RVV se o toolchain suportar):
    cmake ..
    # Para for√ßar build com RVV (requer toolchain compat√≠vel):
    # cmake .. -DRVV_SIMD_FORCE_RVV=ON
    # Para for√ßar build com fallback (√∫til para testes em x86/ARM):
    # cmake .. -DRVV_SIMD_FORCE_FALLBACK=ON
    # Para habilitar build dos bindings Python:
    # cmake .. -DRVV_SIMD_BUILD_PYTHON=ON
    ```

3.  **Compile a biblioteca:**
    ```bash
    make -j$(nproc) # Compila em paralelo
    ```

4.  **(Opcional) Instale a biblioteca:**
    ```bash
    sudo make install # Instala headers e biblioteca no sistema
    ```

### Instalando os Bindings Python

Se voc√™ habilitou a op√ß√£o `DRVV_SIMD_BUILD_PYTHON=ON` no CMake e compilou:

1.  **Navegue at√© o diret√≥rio Python:**
    ```bash
    cd ../python # A partir do diret√≥rio 'build'
    ```

2.  **Instale o pacote Python em modo edit√°vel:**
    ```bash
    pip install -e .
    ```
    Isso cria um link para o m√≥dulo compilado no diret√≥rio `build`, permitindo que voc√™ importe `rvv_simd` em Python.

## Uso da Biblioteca em C++

### Incluindo a Biblioteca

```cpp
#include "rvv_simd.h" // Ou caminho espec√≠fico, e.g., <rvv_simd/vector_ops.h>
```

### Inicializando e Verificando Suporte

```cpp
#include <iostream>
#include "rvv_simd/core.h" // Para fun√ß√µes de inicializa√ß√£o/info

int main() {
    // Inicializa a biblioteca (pode realizar verifica√ß√µes de hardware)
    if (!rvv_simd::initialize()) {
        std::cerr << "Falha ao inicializar a biblioteca RVV-SIMD" << std::endl;
        return 1;
    }

    // Verifica se RVV √© suportado e ativo
    if (rvv_simd::is_rvv_supported()) {
        std::cout << "RVV √© suportado e est√° sendo utilizado." << std::endl;
        std::cout << "Informa√ß√µes RVV: " << rvv_simd::get_rvv_info() << std::endl;
    } else {
        std::cout << "RVV n√£o √© suportado ou desabilitado. Usando implementa√ß√µes de fallback." << std::endl;
    }

    std::cout << "Vers√£o RVV-SIMD: " << rvv_simd::get_version() << std::endl;

    // ... seu c√≥digo aqui ...

    return 0;
}
```

### Opera√ß√µes Vetoriais

```cpp
#include "rvv_simd/vector_ops.h"
#include <vector>
#include <numeric>

// Cria vetores de entrada (exemplo com std::vector)
const size_t size = 1024;
std::vector<float> a(size);
std::vector<float> b(size);
std::vector<float> result(size);

// Inicializa vetores com dados (exemplo)
std::iota(a.begin(), a.end(), 1.0f);
std::iota(b.begin(), b.end(), 0.5f);

// Adi√ß√£o de vetores
rvv_simd::vector_add(a.data(), b.data(), size, result.data());

// Produto escalar
float dot_product = rvv_simd::vector_dot(a.data(), b.data(), size);

// Escalonamento de vetor
rvv_simd::vector_scale(a.data(), 2.5f, size, result.data());

// Normaliza√ß√£o de vetor
rvv_simd::vector_normalize(a.data(), size, result.data());

// Fun√ß√µes de ativa√ß√£o (exemplo com ReLU)
rvv_simd::vector_relu(a.data(), size, result.data());
```

### Opera√ß√µes Matriciais

```cpp
#include "rvv_simd/matrix_ops.h"
#include <vector>

// Cria matrizes de entrada (layout row-major)
const size_t a_rows = 32, a_cols = 64;
const size_t b_rows = 64, b_cols = 32; // b_rows deve ser igual a a_cols
std::vector<float> a_mat(a_rows * a_cols);
std::vector<float> b_mat(b_rows * b_cols);
std::vector<float> c_mat(a_rows * b_cols);

// Inicializa matrizes com dados...

// Multiplica√ß√£o de matrizes (C = A * B)
rvv_simd::matrix_mul(a_mat.data(), b_mat.data(), a_rows, a_cols, b_cols, c_mat.data());

// Transposi√ß√£o de matriz
std::vector<float> a_transpose(a_cols * a_rows);
rvv_simd::matrix_transpose(a_mat.data(), a_rows, a_cols, a_transpose.data());
```

### Opera√ß√µes de Machine Learning

```cpp
#include "rvv_simd/ml_ops.h"
#include <vector>

// Exemplo: Opera√ß√£o de convolu√ß√£o 2D
const size_t input_c = 3, input_h = 32, input_w = 32;
const size_t kernel_n = 16, kernel_h = 3, kernel_w = 3;
const size_t stride_h = 1, stride_w = 1;
const size_t padding_h = 1, padding_w = 1;

std::vector<float> input(input_c * input_h * input_w);
std::vector<float> kernel(kernel_n * input_c * kernel_h * kernel_w);
// Inicializa input e kernel...

// Calcula dimens√µes de sa√≠da
const size_t output_h = (input_h + 2 * padding_h - kernel_h) / stride_h + 1;
const size_t output_w = (input_w + 2 * padding_w - kernel_w) / stride_w + 1;
std::vector<float> output(kernel_n * output_h * output_w);

rvv_simd::convolution_2d(
    input.data(), kernel.data(),
    input_h, input_w, input_c,
    kernel_h, kernel_w, input_c, kernel_n, // Nota: Assumindo layout de kernel NCHW
    stride_h, stride_w,
    padding_h, padding_w,
    output.data()
);

// Exemplo: Max pooling 2D
const size_t pool_h = 2, pool_w = 2;
const size_t pool_stride_h = 2, pool_stride_w = 2;
const size_t pooled_h = (output_h - pool_h) / pool_stride_h + 1;
const size_t pooled_w = (output_w - pool_w) / pool_stride_w + 1;
std::vector<float> pooled(kernel_n * pooled_h * pooled_w);

rvv_simd::max_pooling_2d(
    output.data(),
    output_h, output_w, kernel_n,
    pool_h, pool_w,
    pool_stride_h, pool_stride_w,
    pooled.data()
);
```

## Uso da Biblioteca em Python

### Importando a Biblioteca

```python
import numpy as np
import rvv_simd as rv

# Verifica se a vers√£o com RVV est√° ativa (se aplic√°vel)
print(f"RVV-SIMD Version: {rv.get_version()}")
print(f"RVV Supported: {rv.is_rvv_supported()}")
if rv.is_rvv_supported():
    print(f"RVV Info: {rv.get_rvv_info()}")
```

### Opera√ß√µes Vetoriais

```python
# Cria vetores NumPy (precis√£o float32 √© comum)
size = 1024
a = np.random.uniform(-10, 10, size).astype(np.float32)
b = np.random.uniform(-10, 10, size).astype(np.float32)

# Adi√ß√£o de vetores (aceita e retorna NumPy arrays)
c = rv.vector_add(a, b)
# API alternativa estilo NumPy (se implementada)
# c = rv.add(a, b)

# Produto escalar
dot_product = rv.vector_dot(a, b)
# dot_product = rv.dot(a, b)

# Escalonamento de vetor
scaled = rv.vector_scale(a, 2.5)

# Normaliza√ß√£o de vetor
normalized = rv.vector_normalize(a)

# Fun√ß√µes de ativa√ß√£o
sigmoid_result = rv.sigmoid(a) # Nome hipot√©tico, use o nome real da API
relu_result = rv.relu(a)       # Nome hipot√©tico, use o nome real da API
```

### Opera√ß√µes Matriciais

```python
# Cria matrizes NumPy
rows, cols = 32, 32
a = np.random.uniform(-10, 10, (rows, cols)).astype(np.float32)
b = np.random.uniform(-10, 10, (rows, cols)).astype(np.float32)

# Adi√ß√£o de matrizes
c = rv.matrix_add(a, b)

# Multiplica√ß√£o de matrizes
a_rows, a_cols, b_cols = 32, 64, 32
a_mat = np.random.uniform(-10, 10, (a_rows, a_cols)).astype(np.float32)
b_mat = np.random.uniform(-10, 10, (a_cols, b_cols)).astype(np.float32)

c_mat = rv.matrix_mul(a_mat, b_mat)
# API alternativa estilo NumPy
# c_mat = rv.matmul(a_mat, b_mat)

# Transposi√ß√£o de matriz
a_transpose = rv.matrix_transpose(a)
# a_transpose = rv.transpose(a)
```

### Opera√ß√µes de Machine Learning

```python
# Cria tensor de entrada (ex: NCHW - batch, canais, altura, largura)
# Nota: A API Python pode esperar um layout espec√≠fico. Verifique a documenta√ß√£o.
batch_size = 1 # Exemplo com batch 1
input_channels = 3
input_height = 32
input_width = 32
input_tensor = np.random.uniform(-1, 1, (batch_size, input_channels, input_height, input_width)).astype(np.float32)

# Cria tensor de kernel (ex: NCHW - num_kernels, canais_in, altura, largura)
kernel_num = 16
kernel_height = 3
kernel_width = 3
kernel_tensor = np.random.uniform(-1, 1, (kernel_num, input_channels, kernel_height, kernel_width)).astype(np.float32)

# Opera√ß√£o de convolu√ß√£o
stride = (1, 1)
padding = (1, 1)
# A API pode ter nomes/par√¢metros ligeiramente diferentes. Exemplo:
# output = rv.conv2d(input_tensor, kernel_tensor, stride=stride, padding=padding)
output = rv.convolution_2d(input_tensor[0], kernel_tensor, stride[0], stride[1], padding[0], padding[1]) # Exemplo adaptado da API C++

# Max pooling
pool_size = (2, 2)
stride_pool = (2, 2)
# pooled = rv.max_pool2d(output, kernel_size=pool_size, stride=stride_pool)
pooled = rv.max_pooling_2d(output, pool_size[0], pool_size[1], stride_pool[0], stride_pool[1]) # Exemplo adaptado

# Batch normalization (exemplo de par√¢metros)
channels = pooled.shape[1] # Assumindo NCHW
gamma = np.random.uniform(0.5, 1.5, channels).astype(np.float32)
beta = np.random.uniform(-0.5, 0.5, channels).astype(np.float32)
# mean e var podem ser necess√°rios se a fun√ß√£o n√£o os calcular internamente
mean = np.zeros(channels, dtype=np.float32)
var = np.ones(channels, dtype=np.float32)
epsilon = 1e-5

# normalized = rv.batch_norm(pooled, gamma, beta, mean, var, epsilon) # Nome hipot√©tico
# Verifique a assinatura exata da fun√ß√£o na API Python

# Softmax (exemplo em um vetor achatado)
logits = np.random.uniform(-5, 5, 10).astype(np.float32)
# probabilities = rv.softmax(logits) # Nome hipot√©tico
```

*Nota: Os nomes exatos das fun√ß√µes Python e seus par√¢metros podem variar. Consulte a documenta√ß√£o da API Python da biblioteca.*

## Benchmarks Comparativos

A biblioteca RVV-SIMD inclui um conjunto abrangente de benchmarks para avaliar o desempenho das opera√ß√µes otimizadas para RVV e compar√°-las com:

1.  Implementa√ß√µes escalares de fallback (baseline).
2.  Implementa√ß√µes equivalentes usando extens√µes SIMD de outras arquiteturas (requer compila√ß√£o e execu√ß√£o em hardware correspondente):
    *   **x86**: AVX, AVX2, AVX-512
    *   **ARM**: NEON

### Metodologia de Benchmark

Os benchmarks medem o desempenho de opera√ß√µes chave em diferentes tamanhos de dados para avaliar:

*   **Throughput**: Quantidade de dados processados por segundo (e.g., GFLOPS para opera√ß√µes de ponto flutuante, GB/s para movimenta√ß√£o de dados).
*   **Lat√™ncia**: Tempo m√©dio para completar uma √∫nica opera√ß√£o ou um lote pequeno.
*   **Speedup**: Acelera√ß√£o relativa da implementa√ß√£o RVV em compara√ß√£o com a implementa√ß√£o escalar de fallback e, potencialmente, com implementa√ß√µes AVX/NEON.

As categorias de benchmark incluem:

1.  **Opera√ß√µes Vetoriais Core**: Adi√ß√£o, multiplica√ß√£o, produto escalar, fun√ß√µes matem√°ticas, etc.
2.  **Opera√ß√µes Matriciais**: Adi√ß√£o, multiplica√ß√£o elemento-a-elemento, multiplica√ß√£o de matrizes (GEMM), transposi√ß√£o.
3.  **Opera√ß√µes de Machine Learning**: Convolu√ß√£o 2D, pooling, batch normalization, softmax.

### Executando Benchmarks

Ap√≥s compilar a biblioteca com sucesso:

```bash
cd build
# Certifique-se que o target de benchmark foi compilado (pode ter um nome espec√≠fico)
make rvv_simd_benchmarks # Ou o nome real do target
# Execute o bin√°rio de benchmark
./benchmarks/rvv_simd_benchmarks --benchmark_filter=all # Executa todos os benchmarks
# ./benchmarks/rvv_simd_benchmarks --benchmark_filter=VectorAdd # Executa benchmarks espec√≠ficos
```

Os benchmarks geralmente utilizam bibliotecas como Google Benchmark para fornecer resultados detalhados.

### Exemplo de Resultados (Formato Ilustrativo)

```
--------------------------------------------------------------------
Benchmark                              Time           CPU Iterations
--------------------------------------------------------------------
BM_VectorAdd_RVV/1024              100 ns        100 ns   7000000
BM_VectorAdd_Fallback/1024        1000 ns       1000 ns    700000
BM_MatrixMul_RVV/32x64x32         5000 ns       5000 ns     140000
BM_MatrixMul_Fallback/32x64x32   50000 ns      50000 ns      14000

Compara√ß√£o de Desempenho: Produto Escalar (1M elementos float32)
| Arquitetura       | Tempo (ms) | Speedup vs Fallback | GFLOPS |
|-------------------|------------|---------------------|--------|
| RISC-V (RVV)      |   1.2      |        25.0x        |  1.67  |
| x86 (AVX2)        |   0.8      |        37.5x        |  2.50  | # Exemplo
| ARM (NEON)        |   2.5      |        12.0x        |  0.80  | # Exemplo
| Fallback (Escalar)|  30.0      |         1.0x        |  0.07  |
|-------------------|------------|---------------------|--------|
```

*Nota: Os resultados reais depender√£o do hardware espec√≠fico, compilador, e tamanho dos dados.*

## Aplica√ß√µes em Machine Learning

A RVV-SIMD √© projetada para acelerar componentes computacionalmente intensivos de algoritmos de Machine Learning, especialmente em plataformas RISC-V embarcadas ou servidores onde a efici√™ncia √© crucial.

### Redes Neurais Convolucionais (CNNs)

Opera√ß√µes fundamentais em CNNs, como convolu√ß√µes e pooling, s√£o inerentemente paralelas e se beneficiam enormemente da vetoriza√ß√£o RVV:

*   **Convolu√ß√£o 2D**: Acelerada atrav√©s de algoritmos como `im2col` + GEMM ou abordagens diretas otimizadas com instru√ß√µes RVV (e.g., `vfmacc`).
*   **Pooling (Max/Average)**: Implementa√ß√µes eficientes usando compara√ß√µes e redu√ß√µes vetoriais.
*   **Batch Normalization**: Opera√ß√µes vetoriais de adi√ß√£o, multiplica√ß√£o e divis√£o aplicadas aos canais.
*   **Fun√ß√µes de Ativa√ß√£o**: Aplica√ß√£o elemento-a-elemento de fun√ß√µes como ReLU, Sigmoid, Tanh usando instru√ß√µes vetoriais.
*   **Softmax**: Combina√ß√£o de exponencia√ß√£o vetorial e redu√ß√£o de soma.

### Outros Algoritmos

Al√©m de CNNs, outras √°reas de ML podem se beneficiar:

*   **Processamento de Linguagem Natural (NLP)**: Multiplica√ß√£o de matrizes em Transformers, opera√ß√µes em embeddings.
*   **Redes Neurais Recorrentes (RNNs)**: Multiplica√ß√µes matriz-vetor.
*   **Algoritmos de Clusteriza√ß√£o/Dist√¢ncia**: C√°lculo de dist√¢ncias (Euclidiana, cosseno) entre vetores.
*   **Processamento de Sinais**: FFT, filtros aplicados a dados de sensores.

### Exemplo: Forward Pass de uma CNN Simples (Python)

Este exemplo ilustra como as fun√ß√µes da RVV-SIMD podem ser usadas para construir as camadas de uma CNN simples.

```python
import numpy as np
import rvv_simd as rv

# --- Defini√ß√£o Hipot√©tica de Camadas usando RVV-SIMD ---
class ConvLayer:
    def __init__(self, kernel, stride=1, padding=0):
        self.kernel = kernel.astype(np.float32)
        self.stride = stride
        self.padding = padding

    def forward(self, x):
        # Assume x √© NCHW, kernel √© OutCHW
        # A API Python pode precisar de ajustes no layout ou par√¢metros
        # Exemplo simplificado para batch=1
        if x.ndim == 4: x = x[0] # Processa uma imagem por vez
        return rv.convolution_2d(x, self.kernel,
                                 self.stride, self.stride,
                                 self.padding, self.padding) # Adapte √† API real

class ReLULayer:
    def forward(self, x):
        # Assume que rv.relu opera em todo o tensor ou precisa de loop
        if x.ndim == 3: # CHW
           result = np.zeros_like(x)
           for c in range(x.shape[0]):
               result[c] = rv.relu(x[c].flatten()).reshape(x.shape[1], x.shape[2])
           return result
        elif x.ndim == 1: # Vetor
            return rv.relu(x)
        else:
             raise ValueError("ReLU input shape not supported")


class MaxPoolLayer:
    def __init__(self, kernel_size=2, stride=2):
        self.kernel_size = kernel_size
        self.stride = stride

    def forward(self, x):
         return rv.max_pooling_2d(x, self.kernel_size, self.kernel_size,
                                  self.stride, self.stride) # Adapte √† API real

class FlattenLayer:
    def forward(self, x):
        self.input_shape = x.shape
        return x.flatten()

class LinearLayer:
    def __init__(self, weights, bias):
        self.weights = weights.astype(np.float32) # Out, In
        self.bias = bias.astype(np.float32)       # Out

    def forward(self, x):
        # x √© um vetor (In,)
        # matmul(W, x.T) -> (Out, 1) -> flatten -> (Out,)
        output = rv.matrix_mul(self.weights, x.reshape(-1, 1)).flatten()
        output = rv.vector_add(output, self.bias)
        return output

class SoftmaxLayer:
     def forward(self, x):
         # Assume rv.softmax opera em vetor
         return rv.softmax(x)


# --- Constru√ß√£o e Execu√ß√£o da Rede ---
# Par√¢metros (exemplo)
input_c, input_h, input_w = 3, 32, 32
conv1_f, conv1_k = 16, 3
pool_k = 2
conv2_f, conv2_k = 32, 3
fc1_size = 128
num_classes = 10

# Pesos e Biases (inicializa√ß√£o aleat√≥ria para exemplo)
k1 = np.random.randn(conv1_f, input_c, conv1_k, conv1_k).astype(np.float32)
k2 = np.random.randn(conv2_f, conv1_f, conv2_k, conv2_k).astype(np.float32)
# Calcular tamanho ap√≥s pooling2
final_h = (input_h // pool_k // pool_k)
final_w = (input_w // pool_k // pool_k)
fc1_in_size = conv2_f * final_h * final_w
w1 = np.random.randn(fc1_size, fc1_in_size).astype(np.float32)
b1 = np.random.randn(fc1_size).astype(np.float32)
w_out = np.random.randn(num_classes, fc1_size).astype(np.float32)
b_out = np.random.randn(num_classes).astype(np.float32)

# Cria√ß√£o das camadas
layer1_conv = ConvLayer(k1, padding=1)
layer1_relu = ReLULayer()
layer1_pool = MaxPoolLayer(kernel_size=pool_k, stride=pool_k)
layer2_conv = ConvLayer(k2, padding=1)
layer2_relu = ReLULayer()
layer2_pool = MaxPoolLayer(kernel_size=pool_k, stride=pool_k)
flatten = FlattenLayer()
layer3_fc = LinearLayer(w1, b1)
layer3_relu = ReLULayer()
layer_out = LinearLayer(w_out, b_out)
softmax = SoftmaxLayer()

# Forward Pass
input_data = np.random.randn(1, input_c, input_h, input_w).astype(np.float32) # Batch = 1

x = layer1_conv.forward(input_data)
x = layer1_relu.forward(x)
x = layer1_pool.forward(x)
x = layer2_conv.forward(x)
x = layer2_relu.forward(x)
x = layer2_pool.forward(x)
x = flatten.forward(x)
x = layer3_fc.forward(x)
x = layer3_relu.forward(x)
logits = layer_out.forward(x)
probabilities = softmax.forward(logits)

print("Formato da Sa√≠da (Convolu√ß√£o 1):", layer1_conv.forward(input_data).shape)
print("Formato da Sa√≠da (Pooling 1):", layer1_pool.forward(layer1_relu.forward(layer1_conv.forward(input_data))).shape)
print("Formato da Sa√≠da (Pooling 2):", x.shape) # Ap√≥s Pool2
print("Logits:", logits)
print("Probabilidades:", probabilities)
```

## Otimiza√ß√µes para RVV

A biblioteca RVV-SIMD emprega v√°rias t√©cnicas de otimiza√ß√£o espec√≠ficas da extens√£o vetorial RISC-V para alcan√ßar alto desempenho:

### 1. Adapta√ß√£o Din√¢mica do Comprimento Vetorial (VLA - Vector Length Agnostic)

A RVV permite que o software ajuste o n√∫mero de elementos processados por instru√ß√£o vetorial (`vl`) em tempo de execu√ß√£o, at√© o m√°ximo suportado pelo hardware (`VLEN`). A biblioteca utiliza `vsetvl` (ou `__riscv_vsetvl_e<ew>m<lmul>` intr√≠nseco) no in√≠cio de loops para processar dados em blocos de tamanho ideal, garantindo portabilidade e efici√™ncia em diferentes implementa√ß√µes de RVV.

```cpp
// Exemplo em um loop de adi√ß√£o vetorial
size_t remaining_length = length;
float *pa = a, *pb = b, *pc = result;

while (remaining_length > 0) {
    size_t vl = __riscv_vsetvl_e32m8(remaining_length); // Define vl para o loop atual (at√© M8*VLEN/32 elementos)
    vfloat32m8_t va = __riscv_vle32_v_f32m8(pa, vl);    // Carrega vl elementos de a
    vfloat32m8_t vb = __riscv_vle32_v_f32m8(pb, vl);    // Carrega vl elementos de b
    vfloat32m8_t vc = __riscv_vfadd_vv_f32m8(va, vb, vl); // Adiciona vl elementos
    __riscv_vse32_v_f32m8(pc, vc, vl);                 // Armazena vl elementos em c

    pa += vl; // Avan√ßa ponteiros
    pb += vl;
    pc += vl;
    remaining_length -= vl; // Decrementa contador
}
```

### 2. Padr√µes Eficientes de Acesso √† Mem√≥ria

As instru√ß√µes RVV suportam diferentes modos de acesso √† mem√≥ria:

*   **Unit-stride**: Carrega/armazena elementos cont√≠guos (usado na maioria das opera√ß√µes vetoriais b√°sicas).
*   **Strided**: Acessa elementos com um passo constante (√∫til em certas opera√ß√µes matriciais ou de processamento de sinais).
*   **Indexed**: Acessa elementos usando um vetor de √≠ndices (√∫til para gather/scatter).

A biblioteca prioriza acessos *unit-stride* sempre que poss√≠vel, pois geralmente s√£o os mais r√°pidos. Algoritmos como a multiplica√ß√£o de matrizes ou convolu√ß√µes podem ser reestruturados (e.g., `im2col`) para maximizar o acesso sequencial.

### 3. Opera√ß√µes de Redu√ß√£o Otimizadas

Opera√ß√µes que agregam valores de um vetor (soma, m√°ximo, m√≠nimo, produto escalar) utilizam instru√ß√µes de redu√ß√£o vetorial dedicadas (`vfredusum`, `vfredmax`, etc.). Essas instru√ß√µes s√£o significativamente mais eficientes do que um loop escalar sobre os elementos do vetor.

```cpp
// Exemplo de redu√ß√£o de soma para produto escalar (simplificado)
vfloat32m1_t vsum_res = __riscv_vfmv_s_f_f32m1(0.0f); // Inicializa acumulador (LMUL=1)

size_t remaining_length = length;
float *pa = a, *pb = b;

while (remaining_length > 0) {
    size_t vl = __riscv_vsetvl_e32m8(remaining_length); // Usa LMUL=8 para opera√ß√µes internas
    vfloat32m8_t va = __riscv_vle32_v_f32m8(pa, vl);
    vfloat32m8_t vb = __riscv_vle32_v_f32m8(pb, vl);
    // Acumula√ß√£o vetorial usando vfmacc (Multiply-Accumulate) ou vfmul + vfredusum
    // Exemplo com vfmul + vfredusum:
    vfloat32m8_t vprod = __riscv_vfmul_vv_f32m8(va, vb, vl);
    vsum_res = __riscv_vfredusum_vs_f32m8_f32m1(vprod, vsum_res, vl); // Acumula no registrador LMUL=1

    pa += vl;
    pb += vl;
    remaining_length -= vl;
}
float final_sum = __riscv_vfmv_f_s_f32m1_f32(vsum_res); // Extrai resultado final
```

### 4. Agrupamento de Registradores Vetoriais (LMUL)

O LMUL (Length Multiplier) permite tratar m√∫ltiplos registradores vetoriais como um √∫nico registrador l√≥gico maior (LMUL=2, 4, 8) ou usar fra√ß√µes de um registrador (LMUL=1/2, 1/4, 1/8). A biblioteca pode usar LMUL > 1 para:

*   Aumentar o n√∫mero de elementos processados por itera√ß√£o em loops.
*   Reduzir a sobrecarga de controle de loop.
*   Manter mais dados intermedi√°rios em registradores (√∫til em redu√ß√µes ou algoritmos complexos).

A escolha do LMUL ideal depende da opera√ß√£o espec√≠fica, da disponibilidade de registradores e do `VLEN` do hardware.

### 5. Mascaramento (Predica√ß√£o)

Instru√ß√µes vetoriais podem operar condicionalmente em elementos individuais usando um registrador de m√°scara (geralmente `v0`). Isso √© √∫til para:

*   Implementar l√≥gica condicional (`if`/`else`) em n√≠vel de elemento sem ramifica√ß√µes custosas.
*   Lidar com elementos de borda em loops sem c√≥digo separado.

```cpp
// Exemplo hipot√©tico: result[i] = (a[i] > 0) ? b[i] : c[i];
// vbool4_t mask = __riscv_vmflt_vf_f32m8_b4(va, 0.0f, vl); // Gera m√°scara onde a[i] > 0
// vfloat32m8_t vresult = __riscv_vmerge_vvm_f32m8(vc, vb, mask, vl); // Mescla b[i] (onde mask=1) e c[i] (onde mask=0)
```

Estas otimiza√ß√µes, combinadas, permitem que a RVV-SIMD extraia um desempenho significativo do hardware RISC-V com extens√£o vetorial.

## Alternativas e Compara√ß√£o

Existem outras abordagens para utilizar SIMD em RISC-V:

### 1. SIMD Everywhere (SIMDe)

*   **Abordagem**: Biblioteca de cabe√ßalhos C que emula APIs SIMD de outras arquiteturas (SSE, AVX, NEON) usando C puro ou, quando dispon√≠vel, os intr√≠nsecos da arquitetura alvo (incluindo RVV).
*   **Vantagens**:
    *   Alta portabilidade: Permite compilar c√≥digo SIMD existente (escrito para x86/ARM) em RISC-V.
    *   Reduz o esfor√ßo de migra√ß√£o de c√≥digo legado.
*   **Desvantagens**:
    *   A tradu√ß√£o pode n√£o gerar o c√≥digo RVV mais otimizado.
    *   Pode n√£o explorar totalmente os recursos exclusivos da RVV (como VLA de forma ideal).
    *   A performance depende da qualidade da emula√ß√£o/tradu√ß√£o para RVV.
*   **Refer√™ncia**: [Arxiv: Bringing SIMD Everywhere via Automatic Translation](https://arxiv.org/abs/2309.16509)

### 2. `rvv::experimental::simd` (Exemplo de Biblioteca Nativa)

*   **Abordagem**: Biblioteca C++ que fornece uma API de alto n√≠vel, baseada em templates e inspirada no padr√£o C++ Parallelism TS (`std::experimental::simd`), especificamente para RVV.
*   **Vantagens**:
    *   API moderna e expressiva em C++.
    *   Abstra√ß√£o sobre os intr√≠nsecos RVV.
    *   Potencialmente gera c√≥digo RVV otimizado atrav√©s de templates.
*   **Desvantagens**:
    *   Espec√≠fica para RVV (n√£o port√°vel para x86/ARM sem reescrita).
    *   Pode ser experimental ou ter menos funcionalidades que bibliotecas maduras.
*   **Refer√™ncia**: [GitHub: Pansysk75/cpp-simd-riscv](https://github.com/Pansysk75/cpp-simd-riscv) (Exemplo de implementa√ß√£o)

### 3. Extens√£o RISC-V "P" (Packed SIMD)

*   **Abordagem**: Uma extens√£o RISC-V *diferente* da "V" (Vector). Define opera√ß√µes SIMD de largura fixa (e.g., 32, 64 bits) sobre os registradores inteiros ou de ponto flutuante existentes. Mais similar ao MMX/SSE inicial ou NEON b√°sico.
*   **Vantagens**:
    *   Potencialmente mais simples de implementar em hardware de baixo custo.
    *   API pode ser mais simples que RVV.
*   **Desvantagens**:
    *   Largura fixa (n√£o VLA), menos flex√≠vel e escal√°vel que RVV.
    *   Menor poder computacional por instru√ß√£o comparado a RVV com VLENs maiores.
    *   Ecossistema e suporte de ferramentas ainda em desenvolvimento.
*   **Refer√™ncia**: [GitHub: riscv/riscv-p-spec](https://github.com/riscv/riscv-p-spec)

### Compara√ß√£o RVV-SIMD vs. Alternativas

| Crit√©rio             | RVV-SIMD (Esta Biblioteca)              | SIMDe                                   | `rvv::simd` (Exemplo)                   | Extens√£o "P"          |
| :------------------- | :-------------------------------------- | :-------------------------------------- | :-------------------------------------- | :-------------------- |
| **Foco Principal**   | Otimiza√ß√£o RVV Nativa + Python          | Portabilidade de C√≥digo SIMD Existente | API C++ Moderna para RVV                | SIMD de Largura Fixa  |
| **Portabilidade**    | RISC-V (RVV) + Fallback Escalar         | Multi-arquitetura (x86, ARM, RVV)       | Espec√≠fico RVV                          | Espec√≠fico RISC-V "P" |
| **N√≠vel Abstra√ß√£o**  | M√©dio (API C/Python sobre intr√≠nsecos) | Baixo (APIs de Intr√≠nsecos Emuladas)    | Alto (Templates C++)                    | Baixo (Intr√≠nsecos)   |
| **Desempenho RVV**   | **Alto (Otimizado)**                    | Vari√°vel (Depende da Tradu√ß√£o)          | Potencialmente Alto                     | Moderado (Largura Fixa) |
| **Interface Python** | **Sim (pybind11)**                      | N√£o Diretamente (Via libs C/C++)        | N√£o Diretamente                         | N√£o Diretamente       |
| **Madurez**          | (Definido pelo Projeto)                 | Produ√ß√£o                                | Experimental                            | Em Desenvolvimento    |

**RVV-SIMD** se posiciona como uma solu√ß√£o focada em extrair o m√°ximo desempenho da extens√£o RVV, oferecendo interfaces C++ e Python convenientes, sacrificando a portabilidade direta de c√≥digo SIMD de outras arquiteturas que o SIMDe oferece.

## Estado Atual do Suporte Python (Considera√ß√µes)

A integra√ß√£o direta e eficiente de extens√µes SIMD de baixo n√≠vel como a RVV com uma linguagem de alto n√≠vel como Python apresenta desafios e o suporte atual √© limitado:

1.  **Simuladores Python**: Simuladores RISC-V escritos puramente em Python, como `riscvsim.py`, geralmente **n√£o suportam** a extens√£o vetorial devido √† complexidade de modelar `vl`, `vtype`, LMUL, mascaramento e o grande conjunto de instru√ß√µes vetoriais de forma precisa e perform√°tica em Python.
2.  **Complexidade Arquitetural**: A natureza VLA (Vector Length Agnostic) e configur√°vel da RVV (LMUL, SEW) torna a simula√ß√£o ou a interface direta mais complexa do que SIMD de largura fixa.
3.  **Desempenho**: Chamar opera√ß√µes vetoriais individuais a partir de Python puro teria uma sobrecarga significativa. O desempenho real vem da execu√ß√£o de sequ√™ncias otimizadas de instru√ß√µes RVV em c√≥digo nativo (C/C++), como feito nesta biblioteca RVV-SIMD.
4.  **Abordagem Pr√°tica (Bindings)**: A abordagem mais vi√°vel e perform√°tica, adotada por esta biblioteca, √© implementar o n√∫cleo otimizado em C/C++ usando intr√≠nsecos RVV e expor essa funcionalidade para Python atrav√©s de bindings (e.g., `pybind11`, `Cython`). Isso permite que c√≥digo Python de alto n√≠vel utilize opera√ß√µes vetoriais aceleradas que rodam nativamente.
5.  **Ecossistema**: O suporte RVV em compiladores (GCC, LLVM) e bibliotecas de baixo n√≠vel est√° amadurecendo. Ferramentas Python que dependem dessas cadeias de ferramentas se beneficiar√£o indiretamente. Bibliotecas como NumPy/SciPy n√£o geram c√≥digo RVV diretamente, mas podem ser compiladas com um toolchain RISC-V que pode otimizar *algumas* opera√ß√µes internamente se o compilador suportar auto-vetoriza√ß√£o para RVV (o que ainda √© uma √°rea em desenvolvimento).

Portanto, embora *simular* RVV em Python puro seja limitado, *utilizar* opera√ß√µes RVV otimizadas a partir de Python √© vi√°vel e √© o objetivo principal dos bindings Python desta biblioteca.

## Estrutura do Projeto

```
rvv-simd/
‚îú‚îÄ‚îÄ src/                    # C√≥digo fonte C/C++ da biblioteca core
‚îÇ   ‚îú‚îÄ‚îÄ core/               # Opera√ß√µes SIMD vetoriais e matriciais b√°sicas
‚îÇ   ‚îú‚îÄ‚îÄ ml/                 # Opera√ß√µes espec√≠ficas de Machine Learning (Conv, Pool, etc.)
‚îÇ   ‚îî‚îÄ‚îÄ common/             # Fun√ß√µes utilit√°rias, tipos, detec√ß√£o de RVV
‚îú‚îÄ‚îÄ include/                # Arquivos de cabe√ßalho p√∫blicos (.h ou .hpp)
‚îÇ   ‚îî‚îÄ‚îÄ rvv_simd/           # Cabe√ßalhos organizados por m√≥dulo
‚îú‚îÄ‚îÄ python/                 # Bindings e pacote Python
‚îÇ   ‚îú‚îÄ‚îÄ src/                # C√≥digo C++ para os bindings (usando pybind11)
‚îÇ   ‚îú‚îÄ‚îÄ rvv_simd/           # C√≥digo Python do pacote (se houver, __init__.py etc.)
‚îÇ   ‚îú‚îÄ‚îÄ examples/           # Exemplos de uso em Python
‚îÇ   ‚îî‚îÄ‚îÄ setup.py            # Script para construir e instalar o pacote Python
‚îú‚îÄ‚îÄ benchmarks/             # C√≥digo para os benchmarks de desempenho
‚îÇ   ‚îú‚îÄ‚îÄ core/               # Benchmarks de opera√ß√µes core
‚îÇ   ‚îú‚îÄ‚îÄ ml/                 # Benchmarks de opera√ß√µes ML
‚îÇ   ‚îî‚îÄ‚îÄ common/             # Utilit√°rios para benchmarking
‚îú‚îÄ‚îÄ tests/                  # Testes unit√°rios e de integra√ß√£o (e.g., usando Google Test)
‚îÇ   ‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îú‚îÄ‚îÄ ml/
‚îÇ   ‚îî‚îÄ‚îÄ python/             # Testes para os bindings Python (e.g., usando pytest)
‚îú‚îÄ‚îÄ docs/                   # Documenta√ß√£o (gerada por Doxygen, Sphinx, etc.)
‚îú‚îÄ‚îÄ examples/               # Exemplos de uso da biblioteca em C++
‚îú‚îÄ‚îÄ cmake/                  # M√≥dulos CMake customizados (se houver)
‚îú‚îÄ‚îÄ LICENSE                 # Arquivo de licen√ßa (e.g., MIT)
‚îú‚îÄ‚îÄ README.md               # Este arquivo
‚îú‚îÄ‚îÄ CONTRIBUTING.md         # Diretrizes para contribui√ß√£o
‚îî‚îÄ‚îÄ CMakeLists.txt          # Script principal de build CMake
```

## Contribui√ß√µes

Contribui√ß√µes para a biblioteca RVV-SIMD s√£o muito bem-vindas! Se voc√™ deseja contribuir, por favor:

1.  Verifique as [Issues](https://github.com/<your_username>/rvv-simd/issues) abertas para tarefas existentes ou relate novos bugs/sugest√µes.
2.  Fa√ßa um Fork do reposit√≥rio.
3.  Crie um branch para sua feature ou corre√ß√£o (`git checkout -b feature/nova-operacao` ou `fix/bug-xyz`).
4.  Implemente suas mudan√ßas e adicione testes apropriados.
5.  Certifique-se que os testes passam (`make test` ou `pytest`).
6.  Fa√ßa o commit das suas mudan√ßas (`git commit -m 'Adiciona nova opera√ß√£o X'`).
7.  Fa√ßa o Push para o seu fork (`git push origin feature/nova-operacao`).
8.  Abra um Pull Request para o reposit√≥rio principal.

Por favor, siga as diretrizes detalhadas em [CONTRIBUTING.md](CONTRIBUTING.md) (crie este arquivo se necess√°rio).

## Licen√ßa

Este projeto √© licenciado sob os termos da **Licen√ßa MIT**. Veja o arquivo [LICENSE](LICENSE) para detalhes completos.

## üôè Agradecimentos

- √Ä comunidade RISC-V por seu trabalho na especifica√ß√£o da extens√£o vetorial
- Aos desenvolvedores do pybind11 por facilitar a cria√ß√£o de bindings Python
- √Ä comunidade NumPy por estabelecer padr√µes para computa√ß√£o num√©rica em Python
- A todos os contribuidores que ajudaram a melhorar esta biblioteca

## ‚ùì Perguntas Frequentes

### üîÑ Posso usar RVV-SIMD em hardware n√£o-RISC-V?

Sim, a biblioteca inclui implementa√ß√µes de fallback que funcionam em qualquer arquitetura suportada pelo C++. No entanto, voc√™ n√£o obter√° os benef√≠cios de desempenho da extens√£o vetorial RISC-V.

### üîÑ Como posso verificar se meu hardware suporta RVV?

Em sistemas RISC-V, voc√™ pode verificar se a extens√£o vetorial est√° dispon√≠vel usando:

```bash
cat /proc/cpuinfo | grep isa
```

Se voc√™ ver `rv64gcv` ou similar (com o `v` no final), seu processador suporta a extens√£o vetorial.

### üîÑ A biblioteca funciona com PyTorch ou TensorFlow?

A biblioteca n√£o integra diretamente com PyTorch ou TensorFlow, mas como ela aceita e retorna arrays NumPy, voc√™ pode us√°-la em conjunto com essas frameworks, convertendo tensores para NumPy arrays e vice-versa.

### üîÑ Qual √© a precis√£o num√©rica suportada?

Atualmente, a biblioteca suporta principalmente opera√ß√µes em precis√£o simples (float32). Suporte para precis√£o dupla (float64) e tipos inteiros est√° planejado para vers√µes futuras.

### üîÑ Como posso contribuir com a biblioteca?

Veja a se√ß√£o [Contribui√ß√µes](#-contribui√ß√µes) acima para detalhes sobre como contribuir com o projeto.

---

<p align="center">
  <b>RVV-SIMD: Acelerando o futuro da computa√ß√£o vetorial em RISC-V</b>
</p>